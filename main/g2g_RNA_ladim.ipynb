{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a204ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvelo as scv\n",
    "import dynamo as dyn\n",
    "import numpy as np\n",
    "from anndata import AnnData\n",
    "# import loompy\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from scipy.cluster.hierarchy import fcluster,leaders\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.linalg import inv\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from RKHS import SparseVFC\n",
    "from RKHS import Jacobian_rkhs_gaussian\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd31dd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\76745\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import random\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.csgraph\n",
    "import sklearn.linear_model as sklm\n",
    "import sklearn.metrics as skm\n",
    "import sklearn.model_selection as skms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader, IterableDataset, get_worker_info\n",
    "\n",
    "CHECKPOINT_PREFIX = \"g2g\"\n",
    "\n",
    "from g2g_model_Fisher import *\n",
    "from utils import *\n",
    "# from minepy import MINE\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2813f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9866637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='data/'\n",
    "result_path='results/'\n",
    "adata0=scv.read('DG_bin.h5ad', cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45337c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_arr=adata0.var.index.values\n",
    "X_pca=adata0.obsm['X_pca']\n",
    "X_umap=adata0.obsm['X_umap']\n",
    "cell_vpt=adata0.obs['velocity_pseudotime'].values#adata0.obs['latent_time'].values#\n",
    "Xs=adata0.layers['Ms']#adata.X.A#\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcae617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------data preprocessing\n",
    "k_nei=10\n",
    "adata=adata0.copy()\n",
    "scv.pp.neighbors(adata, n_neighbors=k_nei)\n",
    "scv.pp.pca(adata,n_comps=50)\n",
    "scv.pp.moments(adata, n_pcs=50, n_neighbors=k_nei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "955d6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "row =np.array([np.ones((k_nei,))*i for i in range(adata.shape[0])]).flatten()\n",
    "\n",
    "col=adata.uns['neighbors']['indices'].flatten()\n",
    "\n",
    "w_val=np.array([np.linalg.norm(X_pca[int(i),:]-X_pca[int(j),:]) for i,j in zip(row,col)])\n",
    "\n",
    "adj_val=np.ones(col.shape)\n",
    "\n",
    "A_mat=csr_matrix((adj_val, (row, col)), shape=(adata.shape[0], adata.shape[0]))\n",
    "\n",
    "W_mat=csr_matrix((w_val, (row, col)), shape=(adata.shape[0], adata.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99a1ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "nsamples = 5\n",
    "learning_rate = 1e-3\n",
    "seed = 0\n",
    "# n_workers = 0          ### num_workers数目设置\n",
    "K = 4# !!!!!!!!!! K should be large enough\n",
    "#     checkpoint_path = args.checkpoint\n",
    "#     checkpoints_path = args.checkpoints\n",
    "#     dataset_path = args.dataset6\n",
    "\n",
    "if seed is not None:\n",
    "    reset_seeds(seed)\n",
    "\n",
    "A=A_mat\n",
    "# X=Xs\n",
    "X=Xs/np.mean(np.abs(Xs),axis=0)\n",
    "# X=adata.X.A\n",
    "#--------do not normalize X\n",
    "# scaler=StandardScaler()#\n",
    "# X=scaler.fit_transform(X0_ori)\n",
    "z=cell_vpt\n",
    "\n",
    "n = A.shape[0]\n",
    "train_nodes, val_nodes = train_test_split(n, train_ratio=1.0)\n",
    "#train_nodes, val_nodes = train_test_split(n, train_ratio=0.75)\n",
    "A_train = A[train_nodes, :][:, train_nodes]\n",
    "X_train = X[train_nodes]\n",
    "z_train = z[train_nodes]\n",
    "A_val = A[val_nodes, :][:, val_nodes]\n",
    "X_val = X[val_nodes]\n",
    "z_val = z[val_nodes]\n",
    "\n",
    "train_data = AttributedGraph(A_train, X_train, z_train, K)\n",
    "val_data = AttributedGraph(A_val, X_val, z_val, K)\n",
    "\n",
    "L = 256       ## 稍微大一些，用于寻找 latent dimension\n",
    "encoder = Encoder(X.shape[1], L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad316f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "\n",
    "iterations = epochs ## // n_workers  #不可为0\n",
    "dataset = GraphDataset(train_data, nsamples, iterations)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    # num_workers=n_workers,\n",
    "    worker_init_fn=reset_seeds,\n",
    "    collate_fn=lambda args: args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34344384",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_step = []\n",
    "latent_dim = []\n",
    "non_inc = 0\n",
    "\n",
    "for batch_idx, data in enumerate(loader):\n",
    "    encoder.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = encoder.compute_loss(data[0][0],data[0][1],data[0][2],data[0][3],data[0][4],data[0][5])\n",
    "    \n",
    "    #mu, sigma = encoder.forward(data[0][0])\n",
    "    mu, sigma = encoder(train_data.X)\n",
    "    sigma_aver = torch.sum(sigma,dim = 0)/n\n",
    "\n",
    "    sigma_step.append(sigma_aver.detach().numpy())\n",
    "    if batch_idx% 50 == 0:        \n",
    "        print(batch_idx,loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "sigma_step = np.array(sigma_step)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.xlabel('epoch',fontsize=16,fontweight='bold')\n",
    "plt.ylabel('average σ',fontsize=16,fontweight='bold')\n",
    "\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    if sigma_step[-1,i] < 1:\n",
    "        non_inc += 1\n",
    "        latent_dim.append(i)\n",
    "        plt.plot(range(epochs),sigma_step[:,i], color='red')\n",
    "    elif sigma_step[epochs//2,i] < sigma_step[0,i]:\n",
    "        plt.plot(range(epochs),sigma_step[:,i], color='y')\n",
    "    else:\n",
    "        plt.plot(range(epochs),sigma_step[:,i], color='blue',alpha = 0.5,lw = 1)\n",
    "\n",
    "plt.figure(dpi=600)\n",
    "plt.title('Latent dimensionas = {non_inc}/{L} ,k_hop = {K}'.format(non_inc = non_inc,K = K,L = L))\n",
    "plt.savefig('results/k_nei = {k_nei}&k_hop = {K}&L = {L}.png'.format(k_nei = k_nei,K = K,L = L),dpi = 300)\n",
    "plt.show()\n",
    "print(non_inc)\n",
    "print(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b5ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('results/latent_dim', non_inc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
